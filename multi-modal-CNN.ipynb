{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826871b2-b4c2-4f06-948f-1fc15fb62288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3c6071-6207-4aec-ae90-c48feeaebbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005af1d6-17ab-478f-afef-3f894a3f95f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os.path\n",
    "from PIL import Image\n",
    "from skimage.io import imread, imsave, imshow, show, imread_collection, imshow_collection\n",
    "import os, logging\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '3'  \n",
    "from os import listdir\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "#import keras_tuner as kt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tensorflow import keras\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "os.environ[\"TF_CPP_VMODULE\"]=\"gpu_process_state=10,gpu_cudamallocasync_allocator=10\"\n",
    "a = tf.zeros([], tf.float32)\n",
    "## Imports libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd700ed5-e397-4ff9-b5e8-ff346ea89934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def renameImageFiles(folderpath, prefix,fileExtension):\n",
    "    folder_path = folderpath\n",
    "    new_prefix = prefix\n",
    "\n",
    "    for i, file_path in enumerate(glob.glob(folder_path + '*.'+fileExtension)):\n",
    "        new_file_name = new_prefix + '_' + str(i+1) + '.'+fileExtension\n",
    "        os.rename(file_path, os.path.join(folder_path, new_file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8139e06-0ac5-4a2f-8751-3b023fa16095",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43d606-28a3-4529-bf31-ba5a48804f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = '/home/maxwellsam/Multimodal-COVID19-Images/generatedImages/COVID19/'\n",
    "prefix1 = 'ct_covid'\n",
    "path2 = '/home/maxwellsam/Multimodal-COVID19-Images/generatedImages/NonCOVID19/'\n",
    "prefix2 = 'ct_noncovid'\n",
    "\n",
    "# renameImageFiles(path1, prefix1,'png')\n",
    "# renameImageFiles(path2, prefix2,'png')\n",
    "# renameImageFiles(path2, prefix2,'jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c16b27-c2cb-46a6-ab18-88eebdc78c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "path3 = '/home/maxwellsam/Multimodal-COVID19-Images/dataset/Shap/CT_COVID/'\n",
    "prefix3 = 'ct_covid'\n",
    "path4 = '/home/maxwellsam/Multimodal-COVID19-Images/dataset/Shap/CT_NonCOVID/'\n",
    "prefix4 = 'ct_noncovid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b3c26-6676-47f5-92e7-4028af48b1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImages(imgDirPath, binary_label):\n",
    "    img_names = list()\n",
    "    try:\n",
    "        with os.scandir(imgDirPath) as dirs:\n",
    "            for entry in dirs:\n",
    "                img_names.append(entry.name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error while scanning directory: {e}\")\n",
    "        return None\n",
    "\n",
    "    all_features = []\n",
    "    for img in img_names:\n",
    "        try:\n",
    "            path = imgDirPath + img\n",
    "            cv_img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            if cv_img is None:\n",
    "                print(f\"Error reading image: {path}\")\n",
    "                continue\n",
    "\n",
    "            cv_img2 = cv2.resize(cv_img, (300, 300), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            nFeatures = (cv_img2.shape[0] * cv_img2.shape[1])\n",
    "            features = np.reshape(cv_img2, nFeatures)\n",
    "            all_features.append(features)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {img}: {e}\")\n",
    "\n",
    "    if len(all_features) == 0:\n",
    "        print(\"No valid images found.\")\n",
    "        return None\n",
    "\n",
    "    imgs_df = pd.DataFrame(np.array(all_features), index=img_names)\n",
    "    if binary_label == 0:\n",
    "        imgs_df['class_label'] = np.zeros((imgs_df.shape[0]), dtype=int)\n",
    "    else:\n",
    "        imgs_df['class_label'] = np.ones((imgs_df.shape[0]), dtype=int)\n",
    "\n",
    "    return imgs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c57e34-4ffb-44de-b31c-7d17da669ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_covid_features_df =  processImages(path1,1)#1--> covid-19 positive\n",
    "ct_noncovid_features_df =  processImages(path2,0)#0 ---> covnid-19 negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6301cba6-be1a-4098-a1e8-d888515b4eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_covid_features_df_shap =  processImages(path3,1)#1--> covid-19 positive\n",
    "ct_noncovid_features_df_shap =  processImages(path4,0)#0 ---> covnid-19 negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76129c40-46be-4cdc-9d7d-05b7c271dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvd_imgs = [ct_noncovid_features_df, ct_covid_features_df]\n",
    "cvd_imgs_dataset = pd.concat(cvd_imgs)\n",
    "for i in range(100):\n",
    "    # shuffle the DataFrame rows\n",
    "    cvd_imgs_dataset = cvd_imgs_dataset.sample(frac = 1)\n",
    "# cvd_imgs_dataset_colour = cv2.cvtColor(cvd_imgs_dataset, cv2.COLOR_BGR2RGB)\n",
    "display(cvd_imgs_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0db2820-97c9-4eaa-8278-b66835afa21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvd_imgs_shap = [ct_noncovid_features_df_shap, ct_covid_features_df_shap]\n",
    "cvd_imgs_dataset_shap = pd.concat(cvd_imgs_shap)\n",
    "for i in range(100):\n",
    "    # shuffle the DataFrame rows\n",
    "    cvd_imgs_dataset_shap = cvd_imgs_dataset_shap.sample(frac = 1)\n",
    "# cvd_imgs_dataset_colour = cv2.cvtColor(cvd_imgs_dataset, cv2.COLOR_BGR2RGB)\n",
    "display(cvd_imgs_dataset_shap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da92581f-76e4-4814-9fdb-488a92333af8",
   "metadata": {},
   "source": [
    "#### Prepare negative covid images for machine learning ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c818e-d86d-470e-98b5-54158757cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_x_ = ct_noncovid_features_df.iloc[:,:-1].to_numpy().reshape((2173,300,300,1))\n",
    "#input_data_x = cvd_imgs_dataset.iloc[:,:-1].to_numpy()\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "ct_noncovid_features_df['output_encode'] = label_encoder.fit_transform(ct_noncovid_features_df['class_label'])\n",
    "ct_noncovid_features_df\n",
    "ct_noncovid_features_df = pd.get_dummies(ct_noncovid_features_df, columns =['output_encode'])\n",
    "##Getting the input_labels and input_features for training and testing model\n",
    "output_label_y_ = np.array(ct_noncovid_features_df[['class_label']])\n",
    "# print('Input_x Data: \\n{0}'.format(input_data_x))\n",
    "# print('Output_y Data: \\n{0}'.format(output_label_y))\n",
    "input_data_x_negative_only = input_data_x_\n",
    "output_label_y_negative_only = output_label_y_\n",
    "print('Input_x Data Shape: \\n{0}'.format(input_data_x_negative_only.shape))\n",
    "print('Output_y Data Shape: \\n{0}'.format(output_label_y_negative_only.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dd2e23-c04c-4b28-9905-1cf3a2f13632",
   "metadata": {},
   "source": [
    "#### Prepare positive covid images for machine learning ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bd730d-d06a-4f4c-93c6-0f0e13dd06f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_x__ = ct_covid_features_df.iloc[:,:-1].to_numpy().reshape((2476,300,300,1))\n",
    "#input_data_x = cvd_imgs_dataset.iloc[:,:-1].to_numpy()\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "ct_covid_features_df['output_encode'] = label_encoder.fit_transform(ct_covid_features_df['class_label'])\n",
    "ct_covid_features_df\n",
    "ct_covid_features_df = pd.get_dummies(ct_covid_features_df, columns =['output_encode'])\n",
    "##Getting the input_labels and input_features for training and testing model\n",
    "output_label_y__ = np.array(ct_covid_features_df[['class_label']])\n",
    "# print('Input_x Data: \\n{0}'.format(input_data_x))\n",
    "# print('Output_y Data: \\n{0}'.format(output_label_y))\n",
    "input_data_x_positive_only = input_data_x__\n",
    "output_label_y_positive_only = output_label_y__\n",
    "print('Input_x Data Shape: \\n{0}'.format(input_data_x_positive_only.shape))\n",
    "print('Output_y Data Shape: \\n{0}'.format(output_label_y_positive_only.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40129d3-cfe2-40a7-a92e-7e9d7bcb648d",
   "metadata": {},
   "source": [
    "#### Prepare both positive and negetive covid images for machine learning ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf49cf6-245c-4a59-8057-7b4b085e48a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_x = cvd_imgs_dataset.iloc[:,:-1].to_numpy().reshape((4649,300,300,1))\n",
    "#input_data_x = cvd_imgs_dataset.iloc[:,:-1].to_numpy()\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "cvd_imgs_dataset['output_encode'] = label_encoder.fit_transform(cvd_imgs_dataset['class_label'])\n",
    "cvd_imgs_dataset\n",
    "cvd_imgs_dataset = pd.get_dummies(cvd_imgs_dataset, columns =['output_encode'])\n",
    "##Getting the input_labels and input_features for training and testing model\n",
    "output_label_y = np.array(cvd_imgs_dataset[['output_encode_0','output_encode_1']])\n",
    "# print('Input_x Data: \\n{0}'.format(input_data_x))\n",
    "# print('Output_y Data: \\n{0}'.format(output_label_y))\n",
    "print('Input_x Data Shape: \\n{0}'.format(input_data_x.shape))\n",
    "print('Output_y Data Shape: \\n{0}'.format(output_label_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ee1fee-5c3c-4c83-a2c5-a35c0355ccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvd_imgs_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61627bba-aa64-4e87-a4d2-976474b0d446",
   "metadata": {},
   "source": [
    "#### Prepare both positive and negetive covid shap images for machine learning ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0168f1-b3c6-41d3-afc3-a8823850e0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_x_shap = cvd_imgs_dataset_shap.iloc[:,:-1].to_numpy().reshape((3718,300,300,1))\n",
    "#input_data_x = cvd_imgs_dataset.iloc[:,:-1].to_numpy()\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "cvd_imgs_dataset_shap['output_encode'] = label_encoder.fit_transform(cvd_imgs_dataset_shap['class_label'])\n",
    "cvd_imgs_dataset_shap\n",
    "cvd_imgs_dataset_shap = pd.get_dummies(cvd_imgs_dataset_shap, columns =['output_encode'])\n",
    "##Getting the input_labels and input_features for training and testing model\n",
    "output_label_y_shap = np.array(cvd_imgs_dataset_shap[['output_encode_0','output_encode_1']])\n",
    "# print('Input_x Data: \\n{0}'.format(input_data_x))\n",
    "# print('Output_y Data: \\n{0}'.format(output_label_y))\n",
    "print('Input_x Data Shape: \\n{0}'.format(input_data_x_shap.shape))\n",
    "print('Output_y Data Shape: \\n{0}'.format(output_label_y_shap.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b452f-e552-40ee-bdfe-893f5bdd2d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvd_imgs_dataset_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c34d31-c8e0-479f-af16-f4722620d8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    input_data_x, output_label_y, test_size=.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7896f533-3853-439a-ade0-5b4e89b9dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features_shap, test_features_shap, train_labels_shap, test_labels_shap = train_test_split(\n",
    "    input_data_x_shap, output_label_y_shap, test_size=.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8e42d1-bd16-4051-9046-7f1830455d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features_negative_only, test_features_negative_only, train_labels_negative_only, test_labels_negative_only = train_test_split(\n",
    "    input_data_x_negative_only, output_label_y_negative_only, test_size=.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e890308d-87f8-4c95-9183-731045f992ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features_positive_only, test_features_positive_only, train_labels_positive_only, test_labels__positive_only = train_test_split(\n",
    "    input_data_x_positive_only, output_label_y_positive_only, test_size=.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb3e2f0-c872-4c6c-a696-344eaf751a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_shap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8cdef3-365f-4081-b848-1649400c2f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe390163-fa8f-4705-9401-7a4cf140326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09eaef3-c886-4670-8cab-b63378c1eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 200\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Normalization(),\n",
    "        tf.keras.layers.Resizing(image_size, image_size),\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(factor=0.02),\n",
    "        tf.keras.layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f011e9-ad43-4c1a-a583-9f1b4e60b1b2",
   "metadata": {},
   "source": [
    "### Building the multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ca88b0-b2f3-404e-8048-81a3b80fec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_Mod(inputShape, num_hl, filters_, kernel_size_, stride_poolSize, hl_conv_activation, hl_list, dropout_val, ol_activation):\n",
    "    '''\n",
    "    CNN_Mod(model, num_hl, hl_list, hl_conv_activation, ol_activation, dropout_val, inputShape, filters_, kernel_size_, stride_poolSize):\n",
    "        model            = CNN Model\n",
    "        num_hl           = Number of hidden layers\n",
    "        hl_list          = List of hidden layer units\n",
    "        hl_conv_activation = Activation function for convolutional layers\n",
    "        ol_activation    = Activation function for the output layer\n",
    "        dropout_val      = List of dropout values for hidden layers\n",
    "        inputShape       = Shape of the input data (e.g., (300, 300, 1))\n",
    "        filters_         = Number of filters for Conv layers\n",
    "        kernel_size_     = Size of the kernel (height, width)\n",
    "        stride_poolSize  = Stride and pool size (same value for both)\n",
    "    '''\n",
    "    assert(num_hl == len(hl_list))\n",
    "    assert(num_hl == len(dropout_val))\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=inputShape)\n",
    "\n",
    "    # Augment data (assuming data_augmentation is predefined)\n",
    "    augmented = data_augmentation(inputs)\n",
    "    \n",
    "    conv_layer_1 = tf.keras.layers.Conv2D(filters=filters_, kernel_size=kernel_size_, \n",
    "                                          strides=stride_poolSize, activation=hl_conv_activation)(augmented)\n",
    "    conv_layer_1_max_pool = tf.keras.layers.MaxPooling2D(pool_size=stride_poolSize)(conv_layer_1)\n",
    "    x1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(conv_layer_1_max_pool)\n",
    "\n",
    "    # Convolutional Layer 2 with Max-Pooling\n",
    "    conv_layer_2 = tf.keras.layers.Conv2D(filters=filters_, kernel_size=kernel_size_, \n",
    "                                          strides=stride_poolSize, activation=hl_conv_activation)(x1)\n",
    "    conv_layer_2_max_pool = tf.keras.layers.MaxPooling2D(pool_size=stride_poolSize)(conv_layer_2)\n",
    "    x2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(conv_layer_2_max_pool)\n",
    "\n",
    "    # Flattening the output of the last convolutional block\n",
    "    flatten_layer = tf.keras.layers.Flatten()(x2)\n",
    "\n",
    "    # Adding Dense and Dropout Layers\n",
    "    dense_layers = flatten_layer\n",
    "    for i in range(num_hl):\n",
    "        dense_layers = tf.keras.layers.Dense(units=hl_list[i], activation=hl_conv_activation)(dense_layers)\n",
    "        dense_layers = tf.keras.layers.Dropout(dropout_val[i])(dense_layers)\n",
    "\n",
    "    # Create the CNN model\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=dense_layers)\n",
    "    return model\n",
    "\n",
    "# Define the multimodal model\n",
    "def Multimodal_CNN(inputShape1, inputShape2, num_hl, shared_label_units, \n",
    "                   filters_, kernel_size_, stride_poolSize, hl_conv_activation, hl_list, dropout_val, ol_activation):\n",
    "    # Create two branches\n",
    "    branch1 = CNN_Mod(inputShape1, num_hl, filters_, kernel_size_, stride_poolSize, hl_conv_activation, hl_list, dropout_val, ol_activation)\n",
    "    branch2 = CNN_Mod(inputShape2, num_hl, filters_, kernel_size_, stride_poolSize, hl_conv_activation, hl_list, dropout_val, ol_activation)\n",
    "\n",
    "    # Combine outputs from both branches\n",
    "    combined = tf.keras.layers.Concatenate()([branch1.output, branch2.output])\n",
    "\n",
    "    # Add shared dense layers after combination\n",
    "    x = tf.keras.layers.Dense(units=shared_label_units, activation=hl_conv_activation)(combined)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # Output layer with shared label\n",
    "    final_output = tf.keras.layers.Dense(units=2, activation=ol_activation)(x)\n",
    "\n",
    "    # Define the multimodal model\n",
    "    multimodal_model = tf.keras.Model(inputs=[branch1.input, branch2.input], outputs=final_output)\n",
    "    return multimodal_model\n",
    "\n",
    "# Compile the model\n",
    "def compile_multimodal(model, learning_rate, loss_, metrics_):\n",
    "    '''\n",
    "    def compile_model(model, loss_, learningRate, metrics_):\n",
    "    model: the model to compile\n",
    "    loss_: the loss function\n",
    "    learningRate: learning rate\n",
    "    metrics_: list of metrics to track (e.g., ['accuracy'])\n",
    "    '''\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss_, metrics=metrics_)\n",
    "    return model\n",
    "\n",
    "# Train the multimodal model\n",
    "def train_multimodal(model, val_split_size, batch_size_, numEpochs, patience_, monitor_, mode):\n",
    "    \n",
    "    history = model.fit(\n",
    "        x=[train_features[:2974], train_features_shap],\n",
    "        y=train_labels,\n",
    "        validation_split = val_split_size,\n",
    "        batch_size=batch_size_,\n",
    "        epochs=numEpochs,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(monitor=monitor_, patience=patience_, verbose=1, mode=mode)\n",
    "        ]\n",
    "    )\n",
    "    return history\n",
    "\n",
    "def evaluateModel_loss(history):\n",
    "    print()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend(['Training loss','Validation loss'], loc = 'upper left')\n",
    "    plt.savefig(\"Training_validation_loss_with_i.jpg\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    #plt.show()\n",
    "    print()\n",
    "def evaluateModel_accuracy(history):\n",
    "    print()\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend(['Training Accuracy','Validation Accuracy'], loc = 'upper left')\n",
    "    #plt.show()\n",
    "    plt.savefig(\"Training_validation_accuracy_with_i.jpg\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print()\n",
    "\n",
    "print(CNN_Mod.__doc__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcefb698-a335-4288-b617-b4adde8683b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputShape1 = (300, 300, 1) \n",
    "inputShape2 = (300, 300, 1)  \n",
    "filters_ = 100\n",
    "kernel_size_ = (5, 5)\n",
    "stride_poolSize = 2\n",
    "hl_conv_activation = 'relu'\n",
    "hl_list = [288, 128, 33, 11]  \n",
    "dropout_val = [0.00,0.35,0.00,0.00]\n",
    "ol_activation = 'softmax'\n",
    "shared_label_units = 64\n",
    "learning_rate = 0.0015272304174499124\n",
    "loss_ = 'categorical_crossentropy'\n",
    "metrics_ = ['accuracy']\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "val_split = 0.2\n",
    "patience = 10\n",
    "monitor = 'val_loss'\n",
    "mode = 'min'\n",
    "num_hl = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede5c4e8-3bb0-4a74-bc5e-0910bfff6378",
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_model = Multimodal_CNN(inputShape1, inputShape2, num_hl, shared_label_units, \n",
    "                                  filters_, kernel_size_, stride_poolSize, hl_conv_activation, \n",
    "                                  hl_list, dropout_val, ol_activation)\n",
    "compiled_model = compile_multimodal(multimodal_model, learning_rate, loss_, metrics_)\n",
    "\n",
    "history = train_multimodal(compiled_model,val_split,batch_size,epochs,patience,monitor,mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28726537-896c-48c5-b326-c01f41bae973",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateModel_loss(history)\n",
    "evaluateModel_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27e030e-6b20-4f48-a162-1a49c5a7581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorrectLabel(x):\n",
    "        if x == 0:\n",
    "            return 'Non-Covid'\n",
    "        if x == 1:\n",
    "            return 'Covid'\n",
    "        \n",
    "def D1_to_D2(y_pred):\n",
    "    y_true = {'y_true':[i[0] for i in y_pred]}\n",
    "    y_true_df = pd.DataFrame(y_true)\n",
    "    y_true_df = pd.get_dummies(y_true_df, columns =['y_true'])\n",
    "    output_label_y = np.array(y_true_df[y_true_df.columns])\n",
    "    return output_label_y\n",
    "\n",
    "def getModelEvaluation(model, test_features, test_features_shap, test_labels):\n",
    "    inputs = [test_features, test_features_shap]\n",
    "    predicted_labels = model.predict(inputs)\n",
    "    df = pd.DataFrame(predicted_labels)\n",
    "    df['Predicted_Labels'] = np.array(df.iloc[:,:2]).argmax(axis =1)\n",
    "    df['Predicted_Labels'] = df['Predicted_Labels'].apply(getCorrectLabel)\n",
    "    if (test_labels.shape[1]==2):\n",
    "        df['Actual_Labels'] = test_labels[:,:2].argmax(axis = 1)\n",
    "    else:\n",
    "        df['Actual_Labels'] = D1_to_D2(test_labels)[:,:2].argmax(axis = 1)\n",
    "    df['Actual_Labels'] = df['Actual_Labels'].apply(getCorrectLabel)\n",
    "    # df['Probality'] = np.max(np.array(df.iloc[:,:7]))\n",
    "    #df.drop([0,1,2,3,4,5,6,7,8,9],axis =1,inplace=True)\n",
    "    #print(df.head(100))\n",
    "    cm = pd.crosstab(df.Predicted_Labels, df.Actual_Labels)\n",
    "    fig = plt.figure(figsize=(20,5))\n",
    "    ax1 = plt.subplot(121)\n",
    "    sns.heatmap(cm,annot = True,cmap='Blues')\n",
    "    ax1.set_title('')\n",
    "    # Saving the figure.\n",
    "    plt.savefig(\"test_Confusion_Matrix_with_i.jpg\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    pred = model.evaluate([test_features, test_features_shap],test_labels)\n",
    "    print(\"loss = \" + str(pred[0]))\n",
    "    print(\"test accuracy = \" + str(pred[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849a02d2-558b-46dc-b2af-4fb66869ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_predicted = multimodal_model.predict((test_features[:744], test_features_shap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5143be7d-003e-4562-a4fc-3a1243b1c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    sample_image = test_features[index].reshape(300, 300)\n",
    "    plt.imshow(sample_image, cmap=\"binary\")\n",
    "    plt.title(\"Label:\" + str(test_labels[index].argmax()))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    #sample_image = image_predicted[index].reshape(300, 300)\n",
    "    #plt.imshow(sample_image, cmap=\"binary\")\n",
    "    plt.title(\"Predicted:\" + str(np.argmax(label_predicted[index])))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a12280-79fa-4eac-afc5-c831e42a43e7",
   "metadata": {},
   "source": [
    "#### Test on Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a857d-bbd1-48c3-9212-cb3379c74702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "getModelEvaluation(multimodal_model,test_features,test_features_shap,test_labels)#test_features_negative_onlyshap_, train_labels_shap_, test_labels_shap_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b81d68b-4ced-4cc9-84ad-27de05b2fe60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
